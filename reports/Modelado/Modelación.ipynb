{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto 3 - Modelación\n",
    "**Integrantes:**\n",
    "- Ruth de León, 22428 \n",
    "- Héctor Penedo, 22217 \n",
    "- Rodrigo Mansilla, 22611\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Respuesta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se selecciona como variable de respuesta Caudef, que corresponde al código CIE-10 de la causa de defunción. Esta variable es categórica multinivel –cada código CIE-10 representa una clase distinta– y refleja directamente el desenlace de interés, permitiendo analizar la asociación entre cada causa de muerte y factores socioeconómicos o geográficos.\n",
    "\n",
    "**Partición del conjunto de datos**\n",
    "\n",
    "Con 1 008 732 registros y 66 variables, se implementa un muestreo estratificado sobre Caudef: 70 % de los casos se destina al conjunto de entrenamiento y 30 % al de prueba. La distribución de clases presenta una cola larga: las cinco causas más frecuentes (I219: 7,13 %; J189: 5,41 %; E149: 3,67 %; R98X: 3,29 %; X599: 3,12 %) suman apenas el 22,6 % del total, mientras que el 77,4 % restante se reparte en miles de códigos con muy baja frecuencia, evidenciando un desequilibrio severo de clases.\n",
    "\n",
    "**Limpieza y reducción de dimensionalidad**\n",
    "Para abordar la alta dimensionalidad y los valores erróneos:\n",
    "\n",
    "- Se marcan como NA los valores “999”, “9999” o negativos en variables numéricas (edad, año, etc.).\n",
    "\n",
    "- Se imputan las variables numéricas con la mediana y las categóricas con la moda.\n",
    "\n",
    "- Se eliminan aquellas variables con más del 80 % de valores faltantes o con varianza prácticamente nula.\n",
    "\n",
    "**Codificación y agrupamiento**\n",
    "\n",
    "- Las variables numéricas se normalizan (centrado y escala).\n",
    "\n",
    "- Las variables categóricas se transforman mediante one-hot encoding.\n",
    "\n",
    "- Se agrupan las categorías de baja frecuencia (por ejemplo, municipios con menos del 1 % de observaciones) bajo la etiqueta “Otros” para evitar alta cardinalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. IMPORTS Y RUTAS\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "BASE_DIR = r\"C:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga y Eliminación de variables con observaciones nulas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\AppData\\Local\\Temp\\ipykernel_27780\\1242429795.py:2: DtypeWarning: Columns (15,29,33,34,35,52,53,54,60,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(os.path.join(DATA_DIR, \"master.csv\"))\n"
     ]
    }
   ],
   "source": [
    "# 1. CARGAR DATOS\n",
    "df = pd.read_csv(os.path.join(DATA_DIR, \"master.csv\"))\n",
    "X_raw = df.drop(columns=\"Caudef\")\n",
    "y_raw = df[\"Caudef\"].astype(str)   # homogéneo como string\n",
    "# 2. AGRUPAR CLASES RARAS EN y\n",
    "min_count = 2\n",
    "vc = y_raw.value_counts()\n",
    "raras = vc[vc < min_count].index\n",
    "y = y_raw.replace(raras, \"Otros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partición estratificada 70 / 30 sobre `Caudef`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. SPLIT ESTRATIFICADO 70/30\n",
    "RANDOM_STATE = 123\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_raw, y,\n",
    "    test_size=0.30,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "# 4. IDENTIFICAR VARIABLES\n",
    "numeric_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "\n",
    "# 4.1 Forzar todas las categóricas a str\n",
    "for col in categorical_features:\n",
    "    X_train[col] = X_train[col].astype(str)\n",
    "    X_test [col] = X_test [col].astype(str)\n",
    "# 5. AGRUPAR NIVELES CATEGÓRICOS RAROS (<1% en TRAIN) EN \"Otros\"\n",
    "threshold = 0.01\n",
    "for col in categorical_features:\n",
    "    freqs = X_train[col].value_counts(normalize=True)\n",
    "    rares = freqs[freqs < threshold].index\n",
    "    X_train[col] = X_train[col].where(~X_train[col].isin(rares), other=\"Otros\")\n",
    "    X_test [col] = X_test [col].where(~X_test [col].isin(freqs.index), other=\"Otros\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de pipelines de preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. PIPELINES: IMPUTACIÓN, ESCALADO Y DUMMIES\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler' , StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot' , OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ajuste del preprocesador y transformación de train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train preprocessed: (706112, 241)\n",
      "Test  preprocessed: (302620, 241)\n"
     ]
    }
   ],
   "source": [
    "# 7. AJUSTAR Y TRANSFORMAR\n",
    "X_train_prep = preprocessor.fit_transform(X_train)\n",
    "X_test_prep  = preprocessor.transform(X_test)\n",
    "\n",
    "# Reconstruir DataFrames con nombres de columnas\n",
    "ohe_cols = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
    "all_cols = numeric_features + list(ohe_cols)\n",
    "X_train_prep = pd.DataFrame(X_train_prep, columns=all_cols)\n",
    "X_test_prep  = pd.DataFrame(X_test_prep,  columns=all_cols)\n",
    "\n",
    "print(\"Train preprocessed:\", X_train_prep.shape)\n",
    "print(\"Test  preprocessed:\", X_test_prep.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar a CSV para modelado posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. GUARDAR CSVs\n",
    "os.makedirs(os.path.join(DATA_DIR, \"train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(DATA_DIR, \"test\"),  exist_ok=True)\n",
    "\n",
    "X_train_prep.to_csv(os.path.join(DATA_DIR, \"train\", \"X_train.csv\"), index=False)\n",
    "y_train.to_frame(name=\"Caudef\").to_csv(os.path.join(DATA_DIR, \"train\", \"y_train.csv\"), index=False)\n",
    "X_test_prep .to_csv(os.path.join(DATA_DIR, \"test\" , \"X_test.csv\"),  index=False)\n",
    "y_test .to_frame(name=\"Caudef\") .to_csv(os.path.join(DATA_DIR, \"test\" , \"y_test.csv\"),  index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodología de Modelado con Random Forest (Python / Jupyter)\n",
    "\n",
    "###  Desafíos computacionales y soluciones  \n",
    "Con ~700 000 observaciones y cientos de variables, entrenar un Random Forest presenta un desafio computacional.  \n",
    "\n",
    "**Soluciones propuestas**:  \n",
    "- **Muestreo estratificado**: usar solo un 15–30 % de los datos para el _tuning_ (CV), manteniendo la proporción por `Caudef`.  \n",
    "- **Paralelización**: con `joblib` o el parámetro `n_jobs=-1` de scikit-learn, aprovechar todos los núcleos de CPU.  \n",
    "- **Reducción de árboles** en la fase de tuning (p. ej. 150–300) y simplificación de la grilla de hiperparámetros.  \n",
    "- **Menos pliegues** (5-fold CV) en lugar de 10-fold, equilibrando robustez y tiempo de cómputo.\n",
    "\n",
    "---\n",
    "\n",
    "### Trade-offs sacrificados  \n",
    "\n",
    "| Aspecto                | Pleno rendimiento    | Enfoque actual                  |\n",
    "|------------------------|----------------------|---------------------------------|\n",
    "| # árboles tuning       | 500–1 000            | ~200                            |\n",
    "| Búsqueda hiperparáms   | grillas amplías      | grillas reducidas (2–3 valores) |\n",
    "| Muestra tuning         | 100 % train set      | 15–30 % de train set            |\n",
    "| CV folds               | 10                   | 5                               |\n",
    "\n",
    "_Estos ajustes aceleran el entrenamiento, pero pueden:_  \n",
    "- Pérdida leve de precisión en la selección de hiperparámetros.  \n",
    "- Mayor varianza en la estimación CV.  \n",
    "- Menos estabilidad en la importancia de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m categorical_features = X_train.select_dtypes(include=[\u001b[33m'\u001b[39m\u001b[33mobject\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m]).columns.tolist()\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 2) Pipelines\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m num_tf = \u001b[43mPipeline\u001b[49m([\n\u001b[32m     24\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmedian\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     25\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mscaler\u001b[39m\u001b[33m'\u001b[39m,  StandardScaler())\n\u001b[32m     26\u001b[39m ])\n\u001b[32m     27\u001b[39m cat_tf = Pipeline([\n\u001b[32m     28\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mimputer\u001b[39m\u001b[33m'\u001b[39m, SimpleImputer(strategy=\u001b[33m'\u001b[39m\u001b[33mmost_frequent\u001b[39m\u001b[33m'\u001b[39m)),\n\u001b[32m     29\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mohe\u001b[39m\u001b[33m'\u001b[39m,     OneHotEncoder(handle_unknown=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m     30\u001b[39m ])\n\u001b[32m     32\u001b[39m preprocessor = ColumnTransformer([\n\u001b[32m     33\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, num_tf, numeric_features),\n\u001b[32m     34\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, cat_tf, categorical_features)\n\u001b[32m     35\u001b[39m ])\n",
      "\u001b[31mNameError\u001b[39m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble     import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics      import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot   as plt\n",
    "import numpy               as np\n",
    "import pandas              as pd\n",
    "# 9.2 Cargar datos procesados\n",
    "BASE = r\"C:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\data\"\n",
    "X_train = pd.read_csv(f\"{BASE}/train/X_train.csv\")\n",
    "y_train = pd.read_csv(f\"{BASE}/train/y_train.csv\")[\"Caudef\"]\n",
    "X_test  = pd.read_csv(f\"{BASE}/test/X_test.csv\")\n",
    "y_test  = pd.read_csv(f\"{BASE}/test/y_test.csv\")[\"Caudef\"]\n",
    "RND     = 123  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Muestreo Estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuenta cuántas instancias tiene cada clase  \n",
    "counts = y_train.value_counts()  \n",
    "# Todas las clases con <2 muestras las agrupamos  \n",
    "rare = counts[counts < 2].index  \n",
    "y_train_grouped = y_train.replace(rare, 'Otros')  \n",
    "\n",
    "# (Opcional) si prefieres agrupar por umbral relativo, p.ej. <0.01 del total:  \n",
    "# thr = 0.01 * len(y_train)  \n",
    "# rare = counts[counts < thr].index  \n",
    "# y_train_grouped = y_train.replace(rare, 'Otros')  \n",
    "\n",
    "# %% [markdown]  \n",
    "# ### 9.4 Muestreo estratificado para tuning (15 % de train)  \n",
    "\n",
    "# %%  \n",
    "X_tune, _, y_tune, _ = train_test_split(  \n",
    "    X_train,  \n",
    "    y_train_grouped,  \n",
    "    train_size   = 0.15,  \n",
    "    stratify     = y_train_grouped,  \n",
    "    random_state = RND  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.4 Definir CV y número reducido de árboles\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RND)\n",
    "base_trees = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:805: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 360, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1055, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 839, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Petén'\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 360, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1055, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 839, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Suchitepéquez'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m p      = X_tune.shape[\u001b[32m1\u001b[39m]  \n\u001b[32m      2\u001b[39m model1 = RandomForestClassifier(  \n\u001b[32m      3\u001b[39m     n_estimators     = base_trees,  \n\u001b[32m      4\u001b[39m     max_features     = \u001b[33m\"\u001b[39m\u001b[33msqrt\u001b[39m\u001b[33m\"\u001b[39m,  \n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     random_state     = RND  \n\u001b[32m      8\u001b[39m )  \n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m scores1 = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mModelo 1 CV Accuracy:\u001b[39m\u001b[33m\"\u001b[39m, np.round(scores1,\u001b[32m3\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33m→ mean =\u001b[39m\u001b[33m\"\u001b[39m, np.round(scores1.mean(),\u001b[32m3\u001b[39m))  \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:431\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    411\u001b[39m results = parallel(\n\u001b[32m    412\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    413\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    428\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    429\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n4 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 360, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1055, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 839, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Petén'\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 360, in fit\n    X, y = validate_data(\n           ^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 2961, in validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1370, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1055, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\", line 839, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\rodri\\Documents\\Data-Mining\\Proyecto-3-EDA-Clustering\\venv312\\Lib\\site-packages\\pandas\\core\\generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'Suchitepéquez'\n"
     ]
    }
   ],
   "source": [
    "p      = X_tune.shape[1]  \n",
    "model1 = RandomForestClassifier(  \n",
    "    n_estimators     = base_trees,  \n",
    "    max_features     = \"sqrt\",  \n",
    "    min_samples_leaf = 1,  \n",
    "    n_jobs           = -1,  \n",
    "    random_state     = RND  \n",
    ")  \n",
    "scores1 = cross_val_score(model1, X_tune, y_tune, cv=cv, scoring=\"accuracy\")  \n",
    "print(\"Modelo 1 CV Accuracy:\", np.round(scores1,3), \"→ mean =\", np.round(scores1.mean(),3))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.fit(X_tune, y_tune)  \n",
    "y_pred1  = model1.predict(X_test)  \n",
    "y_proba1 = model1.predict_proba(X_test)  \n",
    "\n",
    "print(\"Confusion Matrix Modelo 1:\\n\", confusion_matrix(y_test, y_pred1))  \n",
    "print(classification_report(y_test, y_pred1, zero_division=0))  \n",
    "\n",
    "plt.figure(figsize=(8,6))  \n",
    "for i, cls in enumerate(model1.classes_):  \n",
    "    fpr, tpr, _ = roc_curve((y_test==cls).astype(int), y_proba1[:,i])  \n",
    "    plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc(fpr,tpr):.2f})\")  \n",
    "plt.plot([0,1],[0,1],\"--\",color=\"grey\")  \n",
    "plt.title(\"ROC Modelo 1\"); plt.legend(loc=\"lower right\"); plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modelo 2: Tuning `max_features` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid2 = {\"max_features\": [\"sqrt\",\"log2\"]}  \n",
    "gs2 = GridSearchCV(  \n",
    "    RandomForestClassifier(  \n",
    "        n_estimators     = base_trees,  \n",
    "        min_samples_leaf = 1,  \n",
    "        n_jobs           = -1,  \n",
    "        random_state     = RND  \n",
    "    ),  \n",
    "    param_grid = param_grid2,  \n",
    "    cv         = cv,  \n",
    "    scoring    = \"accuracy\",  \n",
    "    n_jobs     = -1  \n",
    ")  \n",
    "gs2.fit(X_tune, y_tune)  \n",
    "print(\"Modelo 2 best params:\", gs2.best_params_)  \n",
    "print(\"Modelo 2 CV Accuracy:\", np.round(gs2.best_score_,3))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best2    = gs2.best_estimator_  \n",
    "y_pred2  = best2.predict(X_test)  \n",
    "y_proba2 = best2.predict_proba(X_test)  \n",
    "\n",
    "print(\"Confusion Matrix Modelo 2:\\n\", confusion_matrix(y_test, y_pred2))  \n",
    "print(classification_report(y_test, y_pred2, zero_division=0))  \n",
    "\n",
    "plt.figure(figsize=(8,6))  \n",
    "for i, cls in enumerate(best2.classes_):  \n",
    "    fpr, tpr, _ = roc_curve((y_test==cls).astype(int), y_proba2[:,i])  \n",
    "    plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc(fpr,tpr):.2f})\")  \n",
    "plt.plot([0,1],[0,1],\"--\",color=\"grey\")  \n",
    "plt.title(\"ROC Modelo 2\"); plt.legend(loc=\"lower right\"); plt.show()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: tuning max_features y min_samples_leaf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid3 = {  \n",
    "    \"max_features\"     : [\"sqrt\",\"log2\"],  \n",
    "    \"min_samples_leaf\" : [1,10]  \n",
    "}  \n",
    "gs3 = GridSearchCV(  \n",
    "    RandomForestClassifier(  \n",
    "        n_estimators = base_trees,  \n",
    "        n_jobs       = -1,  \n",
    "        random_state = RND  \n",
    "    ),  \n",
    "    param_grid = param_grid3,  \n",
    "    cv         = cv,  \n",
    "    scoring    = \"accuracy\",  \n",
    "    n_jobs     = -1  \n",
    ")  \n",
    "gs3.fit(X_tune, y_tune)  \n",
    "print(\"Modelo 3 best params:\", gs3.best_params_)  \n",
    "print(\"Modelo 3 CV Accuracy:\", np.round(gs3.best_score_,3))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best3    = gs3.best_estimator_  \n",
    "y_pred3  = best3.predict(X_test)  \n",
    "y_proba3 = best3.predict_proba(X_test)  \n",
    "\n",
    "print(\"Confusion Matrix Modelo 3:\\n\", confusion_matrix(y_test, y_pred3))  \n",
    "print(classification_report(y_test, y_pred3, zero_division=0))  \n",
    "\n",
    "plt.figure(figsize=(8,6))  \n",
    "for i, cls in enumerate(best3.classes_):  \n",
    "    fpr, tpr, _ = roc_curve((y_test==cls).astype(int), y_proba3[:,i])  \n",
    "    plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc(fpr,tpr):.2f})\")  \n",
    "plt.plot([0,1],[0,1],\"--\",color=\"grey\")  \n",
    "plt.title(\"ROC Modelo 3\"); plt.legend(loc=\"lower right\"); plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Comparar distribuciones CV (boxplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.8 Comparar distribuciones CV (boxplot)\n",
    "results = pd.DataFrame({\n",
    "    \"Base\"    : cross_val_score(model1, X_tune, y_tune, cv=cv),\n",
    "    \"Tuning1\" : gs2.cv_results_[\"mean_test_score\"],\n",
    "    \"Tuning2\" : gs3.cv_results_[\"mean_test_score\"]\n",
    "})\n",
    "results.plot.box(grid=True, title=\"CV Accuracy comparado\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = gs3.best_params_  \n",
    "final_rf    = RandomForestClassifier(  \n",
    "    n_estimators     = 400,  \n",
    "    max_features     = best_params[\"max_features\"],  \n",
    "    min_samples_leaf = best_params[\"min_samples_leaf\"],  \n",
    "    n_jobs           = -1,  \n",
    "    random_state     = RND  \n",
    ")  \n",
    "final_rf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluación en test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f  = final_rf.predict(X_test)  \n",
    "y_proba_f = final_rf.predict_proba(X_test)  \n",
    "\n",
    "print(\"Confusion Matrix Modelo Final:\\n\", confusion_matrix(y_test, y_pred_f))  \n",
    "print(classification_report(y_test, y_pred_f, zero_division=0))  \n",
    "\n",
    "plt.figure(figsize=(8,6))  \n",
    "for i, cls in enumerate(final_rf.classes_):  \n",
    "    fpr, tpr, _ = roc_curve((y_test==cls).astype(int), y_proba_f[:,i])  \n",
    "    plt.plot(fpr, tpr, label=f\"{cls} (AUC={auc(fpr,tpr):.2f})\")  \n",
    "plt.plot([0,1],[0,1],\"--\",color=\"grey\")  \n",
    "plt.title(\"ROC Modelo Final\"); plt.legend(loc=\"lower right\"); plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importancia de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(final_rf.feature_importances_, index=X_train.columns)  \n",
    "top20       = importances.nlargest(20)  \n",
    "top20.sort_values().plot.barh(title=\"Top 20 Importancias\"); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (venv)",
   "language": "python",
   "name": "venv312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
